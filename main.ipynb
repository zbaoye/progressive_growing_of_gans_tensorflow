{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from utils import mkdir_p\n",
    "from PGGAN import PGGAN\n",
    "from utils import CelebA, CelebA_HQ, Channel\n",
    "flags = tf.app.flags\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string(\"OPER_NAME\", \"test\", \"the name of experiments\")\n",
    "flags.DEFINE_string(\"path\" , \"/home/zby/datasets/channel/data_5.22\", \"Path of training data, for example /home/hehe/\")\n",
    "flags.DEFINE_string(\"dataset\" , 'channel', \"Path of training data, for example /home/hehe/\")\n",
    "flags.DEFINE_integer(\"batch_size\", 16, \"Batch size\")\n",
    "flags.DEFINE_integer(\"sample_size\", 128, \"Size of sample\")\n",
    "flags.DEFINE_integer(\"epoch\", 10, \"Size of sample\")\n",
    "flags.DEFINE_integer(\"max_iters\", 40000, \"Maxmization of training number\")\n",
    "flags.DEFINE_float(\"learn_rate\", 0.001, \"Learning rate for G and D networks\")\n",
    "flags.DEFINE_integer(\"lam_gp\", 10, \"Weight of gradient penalty term\")\n",
    "flags.DEFINE_float(\"lam_eps\", 0.001, \"Weight for the epsilon term\")\n",
    "flags.DEFINE_integer(\"pg\", 7, \"FLAG of gan training process\")\n",
    "flags.DEFINE_boolean(\"use_wscale\", True, \"Using the scale of weight\")\n",
    "flags.DEFINE_boolean(\"celeba\", True, \"Whether using celeba or using CelebA-HQ\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list file\n",
      "list file ending!\n",
      "('the num of dataset', 50000)\n"
     ]
    }
   ],
   "source": [
    "root_log_dir = \"./output/{}/logs/\".format(FLAGS.OPER_NAME)\n",
    "mkdir_p(root_log_dir)\n",
    "\n",
    "if FLAGS.dataset == 'celeba':\n",
    "    data_In = CelebA(FLAGS.path)\n",
    "elif FLAGS.dataset == 'celeba_hq':\n",
    "    data_In = CelebA_HQ(FLAGS.path)\n",
    "elif FLAGS.dataset == 'channel':\n",
    "    data_In = Channel(FLAGS.path)\n",
    "\n",
    "print (\"the num of dataset\", len(data_In.image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zby/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "current [4, 4, 128] 2048\n",
      "current [3, 3, 128] 1152\n",
      "current [1, 1, 128] 128\n",
      "(16, 4, 4, 2)\n",
      "current [1, 1, 2] 2\n",
      "current [3, 3, 129] 1161\n",
      "current [4, 4, 128] 2048\n",
      "current [128] 128\n",
      "current [1, 1, 2] 2\n",
      "current [3, 3, 129] 1161\n",
      "current [4, 4, 128] 2048\n",
      "current [128] 128\n",
      "current [1, 1, 2] 2\n",
      "current [3, 3, 129] 1161\n",
      "current [4, 4, 128] 2048\n",
      "current [128] 128\n",
      "WARNING:tensorflow:From /home/zby/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "(u'discriminator/dis_y_rgb_conv_4/weight:0', TensorShape([Dimension(1), Dimension(1), Dimension(2), Dimension(128)]))\n",
      "(u'discriminator/dis_y_rgb_conv_4/biases:0', TensorShape([Dimension(128)]))\n",
      "(u'discriminator/dis_n_conv_1_4/weight:0', TensorShape([Dimension(3), Dimension(3), Dimension(129), Dimension(128)]))\n",
      "(u'discriminator/dis_n_conv_1_4/biases:0', TensorShape([Dimension(128)]))\n",
      "(u'discriminator/dis_n_conv_2_4/weight:0', TensorShape([Dimension(4), Dimension(4), Dimension(128), Dimension(128)]))\n",
      "(u'discriminator/dis_n_conv_2_4/biases:0', TensorShape([Dimension(128)]))\n",
      "(u'discriminator/dis_n_fully/weight:0', TensorShape([Dimension(128), Dimension(1)]))\n",
      "(u'discriminator/dis_n_fully/bias:0', TensorShape([Dimension(1)]))\n",
      "('The total para of D', 411521)\n",
      "(u'generator/gen_n_1_conv/weight:0', TensorShape([Dimension(4), Dimension(4), Dimension(128), Dimension(128)]))\n",
      "(u'generator/gen_n_1_conv/biases:0', TensorShape([Dimension(128)]))\n",
      "(u'generator/gen_n_2_conv/weight:0', TensorShape([Dimension(3), Dimension(3), Dimension(128), Dimension(128)]))\n",
      "(u'generator/gen_n_2_conv/biases:0', TensorShape([Dimension(128)]))\n",
      "(u'generator/gen_y_rgb_conv_4/weight:0', TensorShape([Dimension(1), Dimension(1), Dimension(128), Dimension(2)]))\n",
      "(u'generator/gen_y_rgb_conv_4/biases:0', TensorShape([Dimension(2)]))\n",
      "('The total para of G', 410114)\n",
      "('d_vars', 8)\n",
      "('g_vars', 6)\n",
      "('self.d_vars_n_read', 2)\n",
      "('self.g_vars_n_read', 4)\n",
      "('d_vars_n_2_rgb', 0)\n",
      "('g_vars_n_2_rgb', 0)\n",
      "('self.g_d_w', 7)\n",
      "images shuffle\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (16, 64, 64, 2) for Tensor u'Placeholder:0', which has shape '(16, 4, 4, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-11066008bb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpggan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model_PGGan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpggan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zby/Development/progressive_growing_of_gans_tensorflow/PGGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mrealbatch_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrealbatch_array\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlow_realbatch_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrealbatch_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                     \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zby/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zby/anaconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (16, 64, 64, 2) for Tensor u'Placeholder:0', which has shape '(16, 4, 4, 2)'"
     ]
    }
   ],
   "source": [
    "fl = [1,2,2,3,3,4,4,5,5,6,6]\n",
    "r_fl = [1,1,2,2,3,3,4,4,5,5,6]\n",
    "\n",
    "for i in range(FLAGS.pg):\n",
    "\n",
    "    t = False if (i % 2 == 0) else True\n",
    "    pggan_checkpoint_dir_write = \"./output/{}/model_pggan_{}/{}/\".format(FLAGS.OPER_NAME, FLAGS.dataset, fl[i])\n",
    "    sample_path = \"./output/{}/sample_{}_{}\".format(FLAGS.OPER_NAME, FLAGS.dataset, fl[i], t)\n",
    "    mkdir_p(pggan_checkpoint_dir_write)\n",
    "    mkdir_p(sample_path)\n",
    "    pggan_checkpoint_dir_read = \"./output/{}/model_pggan_{}/{}/\".format(FLAGS.OPER_NAME, FLAGS.dataset, r_fl[i])\n",
    "\n",
    "    pggan = PGGAN(batch_size=FLAGS.batch_size, max_iters=FLAGS.max_iters,\n",
    "                  model_path=pggan_checkpoint_dir_write, read_model_path=pggan_checkpoint_dir_read,\n",
    "                  data=data_In, sample_size=FLAGS.sample_size,\n",
    "                  sample_path=sample_path, log_dir=root_log_dir, learn_rate=FLAGS.learn_rate, lam_gp=FLAGS.lam_gp, lam_eps=FLAGS.lam_eps, PG= fl[i],\n",
    "                  t=t, use_wscale=FLAGS.use_wscale, is_celeba=FLAGS.celeba)\n",
    "\n",
    "    pggan.build_model_PGGan()\n",
    "    pggan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
